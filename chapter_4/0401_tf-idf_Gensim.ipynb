{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create some raw documents\n",
    "raw_documents = [\"I love tacos.\",\n",
    "                \"She ran with the chicken.\",\n",
    "                \"I don't choose to take a nap. The nap chooses me.\",\n",
    "                \"That man is nice as pie with ice cream.\",\n",
    "                \"This pizza is an affront to nature.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We are going to need to tokenize, so let's use NLTK\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tokens(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['I', 'love', 'tacos', '.'], ['She', 'ran', 'with', 'the', 'chicken', '.'], ['I', 'do', \"n't\", 'choose', 'to', 'take', 'a', 'nap', '.', 'The', 'nap', 'chooses', 'me', '.'], ['That', 'man', 'is', 'nice', 'as', 'pie', 'with', 'ice', 'cream', '.'], ['This', 'pizza', 'is', 'an', 'affront', 'to', 'nature', '.']]\n"
     ]
    }
   ],
   "source": [
    "# A Gensim document is a list of tokens\n",
    "# We could optionally make all of the tokens lower case\n",
    "gen_docs = [get_tokens(text) for text in raw_documents]\n",
    "print(gen_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num words in dictionary: 32\n",
      "27 This\n",
      "20 That\n",
      "21 as\n",
      "8 ran\n",
      "7 the\n",
      "14 me\n",
      "15 do\n",
      "12 The\n",
      "28 pizza\n",
      "23 is\n",
      "11 n't\n",
      "0 love\n",
      "29 affront\n",
      "17 to\n",
      "1 .\n",
      "25 ice\n",
      "18 chooses\n",
      "19 nice\n",
      "9 choose\n",
      "6 She\n",
      "24 cream\n",
      "22 man\n",
      "16 a\n",
      "2 tacos\n",
      "3 I\n",
      "4 chicken\n",
      "5 with\n",
      "10 nap\n",
      "30 nature\n",
      "13 take\n",
      "31 an\n",
      "26 pie\n"
     ]
    }
   ],
   "source": [
    "# Create dictionary from a list of documents\n",
    "# A dictionary maps every words to a number\n",
    "dictionary = gensim.corpora.Dictionary(gen_docs)\n",
    "num_words = len(dictionary)\n",
    "print(\"Num words in dictionary: {}\".format(num_words))\n",
    "for idx, word in dictionary.items():\n",
    "    print(idx, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "the\n"
     ]
    }
   ],
   "source": [
    "print(dictionary[7])\n",
    "print(dictionary.id2token[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(dictionary.token2id['ran'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 3), (2, 1), (3, 1)]\n"
     ]
    }
   ],
   "source": [
    "# Create bag of words\n",
    "# A bag of words is tf term frequency (tf) of tf-idf\n",
    "# Called a \"bag of words\" because order is lost\n",
    "# Note that \"!\" is not in the dictionary\n",
    "bow_doc = dictionary.doc2bow(['I', 'love', 'love', 'love', 'tacos', '!'])\n",
    "print(bow_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1)], [(1, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1)], [(1, 2), (3, 1), (9, 1), (10, 2), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1)], [(1, 1), (5, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1)], [(1, 1), (17, 1), (23, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1)]]\n"
     ]
    }
   ],
   "source": [
    "# Create corpus\n",
    "# A corpus is a list of bags of words\n",
    "corpus = [dictionary.doc2bow(gen_doc) for gen_doc in gen_docs]\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfModel(num_docs=5, num_nnz=40)\n"
     ]
    }
   ],
   "source": [
    "# Create tf-idf model from corpus\n",
    "# num_nnz is the number of tokens\n",
    "tf_idf = gensim.models.TfidfModel(corpus)\n",
    "print(tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'love', 'tacos', '.']\n",
      "[(0, 1), (1, 1), (2, 1), (3, 1)]\n",
      "[(0, 0.6559486886294514), (2, 0.6559486886294514), (3, 0.37344696513776354)]\n"
     ]
    }
   ],
   "source": [
    "# Show document in text form, bag of words, and tf-idf\n",
    "# 0 is tacos, 1 is love, 2 is I\n",
    "# Value for I is lower because occurs multiple times.\n",
    "# Value for '.' is 0 because it occurs in all sentences and log_2(1) = 0.\n",
    "# Vectors are normalized so they sum to 1\n",
    "print(gen_docs[0])\n",
    "print(corpus[0])\n",
    "print(tf_idf[corpus][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (3, 1), (28, 1)]\n",
      "[(0, 0.6559486886294514), (3, 0.37344696513776354), (28, 0.6559486886294514)]\n"
     ]
    }
   ],
   "source": [
    "# Show bag of words and tf-idf for new document\n",
    "# Note it is similar to the document above\n",
    "bow = dictionary.doc2bow(['I', 'love', 'pizza', '.'])\n",
    "print(bow)\n",
    "print(tf_idf[bow])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity index with 5 documents in 0 shards (stored under ~/Documents/nlp-python/similarity)\n"
     ]
    }
   ],
   "source": [
    "# Create similarity measure object in tf-idf space\n",
    "# First arg is temp external storage\n",
    "# https://radimrehurek.com/gensim/similarities/docsim.html\n",
    "sims = gensim.similarities.Similarity('~/Documents/nlp-python/similarity', tf_idf[corpus],\n",
    "                                     num_features=len(dictionary))\n",
    "print(sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chicken', 'with', 'taco', 'love']\n",
      "[(0, 1), (4, 1), (5, 1)]\n",
      "[(0, 0.6559486886294514), (4, 0.6559486886294514), (5, 0.37344696513776354)]\n"
     ]
    }
   ],
   "source": [
    "# Create query document and convert to tf-idf\n",
    "query_doc = \"chicken with taco love\".split()\n",
    "print(query_doc)\n",
    "query_doc_bow = dictionary.doc2bow(query_doc)\n",
    "print(query_doc_bow)\n",
    "query_doc_tf_idf = tf_idf[query_doc_bow]\n",
    "print(query_doc_tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.4302687 ,  0.41768694,  0.        ,  0.07687882,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims[query_doc_tf_idf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
